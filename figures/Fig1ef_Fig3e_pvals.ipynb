{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_pickle(\"../../data/tts/y_test_ord.pkl\")\n",
    "\n",
    "# Blast deduplicates lab labels if multiple hits are from same lab.\n",
    "blast = np.load(\"../../data/blast/firstorder_blast_test_predictions.npy\")\n",
    "ours = np.load(\"../../data/results/TEST_100_sub_MLP_full_with_metadata_300300.npy\")\n",
    "ours_no_pheno = np.load(\"../../data/results/TEST_100_sub_nometadata_201300.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topkacc(pred,true,k):\n",
    "    topkclasses = np.argsort(pred)[:,-k:]\n",
    "    correct = ((topkclasses == true[:,None]).any(axis=1))\n",
    "    accuracy = np.sum(correct) / len(true)\n",
    "    return accuracy\n",
    "\n",
    "def blastacc(predictions, true):\n",
    "    top1_prediction = np.array([a[0] if len(a) != 0 else 9999999 for a in predictions])\n",
    "    correct = (top1_prediction == true)\n",
    "    return np.mean(correct)\n",
    "    \n",
    "def blastacc10(predictions, true):\n",
    "    correct = [true[i] in predictions[i] if len(predictions[i]) != 0 else 9999999 for i in range(len(true))]\n",
    "    return np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_metric(metric_func, pred, true, n=30, frac=50):\n",
    "    \"\"\"\n",
    "    Returns the average and standard deviation of metric_func \n",
    "    evaluated on n resamples of frac proportion of test set.\n",
    "    \n",
    "    metric_func must have the signature\n",
    "    metric_func(np.array(predictions), np.array(true))\n",
    "    \"\"\"\n",
    "    length = len(true)\n",
    "    assert len(pred) == length\n",
    "    if len(pred) == 0:\n",
    "        return (0,0)\n",
    "    \n",
    "    index = np.arange(length)\n",
    "    samples = []\n",
    "    for i in range(n):\n",
    "        subidx = np.random.choice(index, size=length, replace=False)\n",
    "        samples.append(\n",
    "            metric_func(pred[index], true[index])\n",
    "        )\n",
    "    return np.mean(samples), np.std(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First top 1\n",
    "ours_mean, ours_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=1),\n",
    "    ours, y\n",
    ")\n",
    "\n",
    "blast_mean, blast_std = resample_metric(\n",
    "    blastacc,\n",
    "    blast, y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind_from_stats(\n",
    "mean1=ours_mean, std1=ours_std, nobs1=30,\n",
    "mean2=blast_mean, std2=blast_std, nobs2=30, equal_var=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10\n",
    "ours_mean, ours_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=10),\n",
    "    ours, y\n",
    ")\n",
    "\n",
    "blast_mean, blast_std = resample_metric(\n",
    "    blastacc10,\n",
    "    blast, y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind_from_stats(\n",
    "mean1=ours_mean, std1=ours_std, nobs1=30,\n",
    "mean2=blast_mean, std2=blast_std, nobs2=30, equal_var=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Compare +/- phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First top 1\n",
    "ours_mean, ours_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=1),\n",
    "    ours, y\n",
    ")\n",
    "\n",
    "ours_seq_mean, ours_seq_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=1),\n",
    "    ours_no_pheno, y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind_from_stats(\n",
    "mean1=ours_mean, std1=ours_std, nobs1=30,\n",
    "mean2=ours_seq_mean, std2=ours_seq_std, nobs2=30, equal_var=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10\n",
    "# First top 1\n",
    "ours_mean, ours_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=10),\n",
    "    ours, y\n",
    ")\n",
    "\n",
    "ours_seq_mean, ours_seq_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=10),\n",
    "    ours_no_pheno, y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind_from_stats(\n",
    "mean1=ours_mean, std1=ours_std, nobs1=30,\n",
    "mean2=ours_seq_mean, std2=ours_seq_std, nobs2=30, equal_var=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now fig 3 e (countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = pd.read_pickle(\"../../data/tts/y_test_country.pkl\")\n",
    "blast = np.load(\"../../country_blast_test_predictions.npy\")\n",
    "ours = np.load(\"../../data/results/rf/predictions_TEST_countries_seq_meta_nous.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop US \n",
    "mask = ~(y == 33)\n",
    "y = y[mask]\n",
    "blast = blast[mask]\n",
    "ours = ours[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First top 1\n",
    "ours_mean, ours_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=1),\n",
    "    ours, y\n",
    ")\n",
    "\n",
    "blast_mean, blast_std = resample_metric(\n",
    "    blastacc,\n",
    "    blast, y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind_from_stats(\n",
    "mean1=ours_mean, std1=ours_std, nobs1=30,\n",
    "mean2=blast_mean, std2=blast_std, nobs2=30, equal_var=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10\n",
    "ours_mean, ours_std = resample_metric(\n",
    "    lambda x,y1: topkacc(x,y1,k=10),\n",
    "    ours, y\n",
    ")\n",
    "\n",
    "blast_mean, blast_std = resample_metric(\n",
    "    blastacc10,\n",
    "    blast, y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind_from_stats(\n",
    "mean1=ours_mean, std1=ours_std, nobs1=30,\n",
    "mean2=blast_mean, std2=blast_std, nobs2=30, equal_var=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
