{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random_forest_ancestor_lab.ipynb\n",
    "Predict the ancestor lab from sequence and metadata.\n",
    "\n",
    "This code is RAM intensive. Start an AWS instance with sufficient resources (we recommend r5.metal or m5.24xlarge for shortest runtime - the code takes advantage of all the available CPU cores) with Ubuntu Server 18.04 LTS AMI (for example, ami-0f65671a86f061fcd). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "%pylab inline\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../data/tts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b0f51dea7ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x_train_SO_fixed.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x_test_SO_fixed.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_val_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x_val_SO_fixed.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_train_SO_fixed.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_raw = pd.read_pickle(os.path.join(path, 'x_train_SO_fixed.pkl'))\n",
    "X_test_raw = pd.read_pickle(os.path.join(path, 'x_test_SO_fixed.pkl'))\n",
    "X_val_raw = pd.read_pickle(os.path.join(path, 'x_val_SO_fixed.pkl'))\n",
    "\n",
    "y_train = pd.read_pickle(os.path.join(path, 'y_train_SO_fixed.pkl'))\n",
    "#y_test = pd.read_pickle(os.path.join(path, 'y_test_SO_fixed.pkl'))\n",
    "y_val = pd.read_pickle(os.path.join(path, 'y_val_SO_fixed.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmeta = X_train_raw.loc[:,np.setdiff1d(X_train_raw.columns,['sequence'])].values\n",
    "valmeta = X_val_raw.loc[:,np.setdiff1d(X_val_raw.columns,['sequence'])].values\n",
    "testmeta = X_test_raw.loc[:,np.setdiff1d(X_test_raw.columns,['sequence'])].values\n",
    "\n",
    "ngram_start, ngram_end = 1, 4\n",
    "tfidf_14 = TfidfVectorizer(analyzer='char', ngram_range=(ngram_start, ngram_end))\n",
    "\n",
    "trainseq_tfidf_14 = tfidf_14.fit_transform(X_train_raw.sequence)\n",
    "\n",
    "valseq_tfidf_14 = tfidf_14.transform(X_val_raw.sequence)\n",
    "testseq_tfidf_14 = tfidf_14.transform(X_test_raw.sequence)\n",
    "\n",
    "X_train_14 = np.concatenate([trainseq_tfidf_14.todense(), trainmeta], axis=1)\n",
    "X_val_14 = np.concatenate([valseq_tfidf_14.todense(), valmeta], axis=1)\n",
    "X_test_14 = np.concatenate([testseq_tfidf_14.todense(), testmeta], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seqonly_14 = trainseq_tfidf_14.todense()\n",
    "X_val_seqonly_14 = valseq_tfidf_14.todense()\n",
    "X_test_seqonly_14 = testseq_tfidf_14.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    'seq_meta': {\n",
    "        'train_X': X_train_14,\n",
    "        'train_y': y_train,\n",
    "        'val_X': X_val_14,\n",
    "        'val_y': y_val,\n",
    "        'test_X': X_test_14,\n",
    "        #'test_y': y_test\n",
    "    },\n",
    "    'seqonly':{\n",
    "        'train_X': X_train_seqonly_14,\n",
    "        'train_y': y_train,\n",
    "        'val_X': X_val_seqonly_14,\n",
    "        'val_y': y_val,\n",
    "        'test_X': X_test_seqonly_14,\n",
    "        #'test_y': y_test\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_params = {'class_weight': 'balanced',\n",
    " 'max_features': 0.5,\n",
    " 'n_estimators': 1000,\n",
    " 'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_simple = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_meta\n",
      "1.0\n",
      "0.8830811554332875\n",
      "seqonly\n",
      "1.0\n",
      "0.8262265016047684\n"
     ]
    }
   ],
   "source": [
    "for key in configurations.keys():\n",
    "\n",
    "    val = configurations[key]\n",
    "    models_simple[key] = RandomForestClassifier(**reasonable_params)\n",
    "\n",
    "    print(key)\n",
    "    models_simple[key].fit(val['train_X'], val['train_y'])\n",
    "    print(models_simple[key].score(val['train_X'], val['train_y']))\n",
    "    print(models_simple[key].score(val['val_X'], val['val_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in configurations.keys():\n",
    "    model = joblib.dump(models_simple[key], f\"model_{key}_second_order_fixed.joblibpkl\")\n",
    "    np.save(f\"./predictions_val_second_order_fixed_{key}_simplemodel.npy\", models_simple[key].predict_proba(configurations[key]['val_X']))\n",
    "\n",
    "    np.save(f\"./predictions_TEST_second_order_fixed_{key}_simplemodel.npy\", models_simple[key].predict_proba(configurations[key]['test_X']))\n",
    "\n",
    "    np.save(f\"./predictions_train_second_order_fixed_{key}_simplemodel.npy\", models_simple[key].predict_proba(configurations[key]['train_X']))\n",
    "    \n",
    "    np.save(f\"./classes_for_predictions_second_order_fixed_{key}_simplemodel.npy\", models_simple[key].classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/attrib/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/miniconda3/envs/attrib/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6775007647598654\n",
      "0.6153140761118753\n",
      "seqonly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/attrib/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/miniconda3/envs/attrib/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29053227286632\n",
      "0.2640990371389271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/attrib/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for key in configurations.keys():\n",
    "    val = configurations[key]\n",
    "    print(key)\n",
    "    model = LogisticRegression(penalty='l1', class_weight='balanced')\n",
    "    model.fit(val['train_X'], val['train_y'])\n",
    "    print(model.score(val['train_X'], val['train_y']))\n",
    "    print(model.score(val['val_X'], val['val_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18331293973692261"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts().iloc[0] / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
