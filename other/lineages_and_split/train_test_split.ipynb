{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in addgene pickle files\n",
    "basedir = '../../../data/'\n",
    "id2lineage = pd.read_pickle(os.path.join(basedir,'lineages/id2lineage.pickle'))\n",
    "id2lineage = id2lineage.reset_index()\n",
    "\n",
    "addgene_full2 = pd.read_pickle(basedir,'full/addgene_full.pickle')\n",
    "addgene_full2 = addgene_full2.reset_index()\n",
    "\n",
    "lin2id = pd.read_pickle(os.path.join(basedir,'lineages/lineage2ids.pickle'))\n",
    "lin2id = lin2id.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop lineages with only one unique lab present\n",
    "\n",
    "#Make DF of lineages, unique_num_labs\n",
    "lab_per_lin = pd.DataFrame(columns=['lineage','num_unique_labs'])\n",
    "num_lab_per_lin = []\n",
    "for lineage in lin2id['lineage']:\n",
    "    lin_only = addgene_full2.loc[addgene_full2['lineage'] == lineage]\n",
    "    num_lab_per_lin.append(lin_only['lab'].nunique())\n",
    "lab_per_lin['lineage'] = lin2id['lineage']\n",
    "lab_per_lin['num_unique_labs'] = num_lab_per_lin\n",
    "\n",
    "#Get bad Lineages with only 1 lab \n",
    "bad_lin = lab_per_lin.loc[lab_per_lin['num_unique_labs'] <= 1]\n",
    "bad_lin = bad_lin.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace bad_lineagues and save news files for addgene_full and id2lineage and lineage2id\n",
    "id2lineage = id2lineage.loc[-id2lineage['lineage'].isin(bad_lin['lineage'])]\n",
    "id2lineage = id2lineage.reset_index(drop = True)\n",
    "\n",
    "lin2id = lin2id.loc[-lin2id['lineage'].isin(bad_lin['lineage'])]\n",
    "lin2id = lin2id.reset_index(drop = True)\n",
    "\n",
    "addgene_full2.loc[addgene_full2['lineage'].isin(bad_lin['lineage']), 'lineage'] = np.NaN\n",
    "addgene_full2 = addgene_full2.reset_index(drop = True)\n",
    "\n",
    "lin2id.to_pickle('lineage2ids_no_bad_lin.pickle')\n",
    "id2lineage.to_pickle('id2lineage_no_bad_lin.pickle')\n",
    "addgene_full2.to_pickle(\"addgene_full_no_bad_lin.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group all labs with under ten plasmids into one large lab class named Unk Engineered\n",
    "\n",
    "#Convert value count to df\n",
    "counts_df = addgene_full2['lab'].value_counts()\n",
    "counts_df = counts_df.to_frame().reset_index()\n",
    "counts_df.rename(columns={'index': 'lab', 'lab': 'value_count'}, inplace=True)\n",
    "\n",
    "#Find all rows with under 10 value_count\n",
    "low_abund = counts_df.loc[counts_df['value_count'] < 10]\n",
    "\n",
    "#Replace all low abundance lab names with Unk Egineered\n",
    "addgene_full2.loc[addgene_full2['lab'].isin(low_abund['lab']),['lab']] = 'Unk Engineered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding test baseline and adding more to Unk Egineering\n",
    "\n",
    "#Create DF with labs and number of unique lineages per lab\n",
    "lin_per_lab = pd.DataFrame(columns=['lab', 'num_unique_lin'])\n",
    "num_lin_per_lab = []\n",
    "\n",
    "#Iterate over lab and get df with only a specific lab then find number of unique lineages within that df\n",
    "for lab in addgene_full2['lab'].unique():\n",
    "    lab_only = addgene_full2.loc[addgene_full2['lab'] == lab]\n",
    "    num_lin_per_lab.append(lab_only['lineage'].nunique())\n",
    "\n",
    "lin_per_lab['lab'] =  addgene_full2['lab'].unique()\n",
    "lin_per_lab['num_unique_lin'] = num_lin_per_lab\n",
    "\n",
    "#Important: Sort lin_per_lab  by num_unique_lin ascending = True as it forces 'Unk Engineered' to be at bottom\n",
    "lin_per_lab = lin_per_lab.sort_values(by = 'num_unique_lin')\n",
    "lin_per_lab = lin_per_lab.reset_index(drop = True)\n",
    "\n",
    "test_baseline = pd.DataFrame()\n",
    "for lab in lin_per_lab['lab']:\n",
    "    lab_plasmids = addgene_full2.loc[addgene_full2['lab'] == lab]\n",
    "    no_lin_membership = lab_plasmids.loc[lab_plasmids['lineage'].isnull()]\n",
    "    if no_lin_membership.shape[0] < 3:\n",
    "        #Replace Lab name with 'Unk Engineered' and update lin_per-lab with new Unk value\n",
    "        addgene_full2.loc[addgene_full2['lab'] == lab,['lab']] = 'Unk Engineered'\n",
    "    else: \n",
    "        #Sample 3 random plasmids from no lineage membership and put them into baseline test set \n",
    "        test_baseline = test_baseline.append(no_lin_membership.sample(n=3,random_state=69))\n",
    "test_baseline = test_baseline.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the updated addgene_full2 \n",
    "addgene_full2.to_pickle(\"addgene_full_no_bad_lin_baseline.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all ids with lineage\n",
    "ids_with_lineage = id2lineage['addgene_id'].drop_duplicates()\n",
    "\n",
    "#Find all unique lineage labels\n",
    "unique_lineage_labels = id2lineage['lineage'].drop_duplicates()\n",
    "\n",
    "#Find all ids \n",
    "all_ids = addgene_full2['addgene_id'].drop_duplicates()\n",
    "\n",
    "#All plasmid ids that do not have a lineage\n",
    "no_lineage_plasmids = all_ids[~all_ids.isin(ids_with_lineage)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addgene_id</th>\n",
       "      <th>lineage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>36935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>56047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>65266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>35072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>12032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43.0</td>\n",
       "      <td>41039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.0</td>\n",
       "      <td>45698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45.0</td>\n",
       "      <td>4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46.0</td>\n",
       "      <td>10780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47.0</td>\n",
       "      <td>64772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48.0</td>\n",
       "      <td>2746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49.0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>51.0</td>\n",
       "      <td>16352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>52.0</td>\n",
       "      <td>38504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1015.0</td>\n",
       "      <td>16728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>42068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1028.0</td>\n",
       "      <td>98748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1029.0</td>\n",
       "      <td>86405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>5986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1031.0</td>\n",
       "      <td>83211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1032.0</td>\n",
       "      <td>10033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1084.0</td>\n",
       "      <td>18996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1086.0</td>\n",
       "      <td>36897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1087.0</td>\n",
       "      <td>97895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1088.0</td>\n",
       "      <td>21501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1089.0</td>\n",
       "      <td>28957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1090.0</td>\n",
       "      <td>95318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1091.0</td>\n",
       "      <td>57449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1092.0</td>\n",
       "      <td>11124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81804</th>\n",
       "      <td>115198.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81805</th>\n",
       "      <td>115199.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81806</th>\n",
       "      <td>115200.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81807</th>\n",
       "      <td>115201.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81808</th>\n",
       "      <td>115202.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81809</th>\n",
       "      <td>115203.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81810</th>\n",
       "      <td>115204.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81811</th>\n",
       "      <td>115205.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81812</th>\n",
       "      <td>115232.0</td>\n",
       "      <td>5481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81813</th>\n",
       "      <td>115233.0</td>\n",
       "      <td>72767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81814</th>\n",
       "      <td>115234.0</td>\n",
       "      <td>84771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81815</th>\n",
       "      <td>115235.0</td>\n",
       "      <td>59932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81816</th>\n",
       "      <td>115236.0</td>\n",
       "      <td>75356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81817</th>\n",
       "      <td>115245.0</td>\n",
       "      <td>48378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81818</th>\n",
       "      <td>115246.0</td>\n",
       "      <td>6512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81819</th>\n",
       "      <td>115247.0</td>\n",
       "      <td>76978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81820</th>\n",
       "      <td>115248.0</td>\n",
       "      <td>93870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81821</th>\n",
       "      <td>115249.0</td>\n",
       "      <td>71912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81822</th>\n",
       "      <td>115252.0</td>\n",
       "      <td>34108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81823</th>\n",
       "      <td>115253.0</td>\n",
       "      <td>35929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81824</th>\n",
       "      <td>115254.0</td>\n",
       "      <td>24939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81825</th>\n",
       "      <td>115255.0</td>\n",
       "      <td>37494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81826</th>\n",
       "      <td>115256.0</td>\n",
       "      <td>51289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81827</th>\n",
       "      <td>115257.0</td>\n",
       "      <td>7715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81828</th>\n",
       "      <td>115258.0</td>\n",
       "      <td>3938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81829</th>\n",
       "      <td>115259.0</td>\n",
       "      <td>13779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81830</th>\n",
       "      <td>115260.0</td>\n",
       "      <td>81884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81831</th>\n",
       "      <td>115261.0</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81832</th>\n",
       "      <td>115262.0</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81833</th>\n",
       "      <td>115265.0</td>\n",
       "      <td>49627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81834 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       addgene_id  lineage\n",
       "0             3.0    36935\n",
       "1             4.0    56047\n",
       "2             6.0    65266\n",
       "3            41.0    35072\n",
       "4            42.0    12032\n",
       "5            43.0    41039\n",
       "6            44.0    45698\n",
       "7            45.0     4130\n",
       "8            46.0    10780\n",
       "9            47.0    64772\n",
       "10           48.0     2746\n",
       "11           49.0      143\n",
       "12           50.0      143\n",
       "13           51.0    16352\n",
       "14           52.0    38504\n",
       "15         1015.0    16728\n",
       "16         1026.0    42068\n",
       "17         1028.0    98748\n",
       "18         1029.0    86405\n",
       "19         1030.0     5986\n",
       "20         1031.0    83211\n",
       "21         1032.0    10033\n",
       "22         1084.0    18996\n",
       "23         1086.0    36897\n",
       "24         1087.0    97895\n",
       "25         1088.0    21501\n",
       "26         1089.0    28957\n",
       "27         1090.0    95318\n",
       "28         1091.0    57449\n",
       "29         1092.0    11124\n",
       "...           ...      ...\n",
       "81804    115198.0      512\n",
       "81805    115199.0      512\n",
       "81806    115200.0      512\n",
       "81807    115201.0      512\n",
       "81808    115202.0      512\n",
       "81809    115203.0      512\n",
       "81810    115204.0      512\n",
       "81811    115205.0      512\n",
       "81812    115232.0     5481\n",
       "81813    115233.0    72767\n",
       "81814    115234.0    84771\n",
       "81815    115235.0    59932\n",
       "81816    115236.0    75356\n",
       "81817    115245.0    48378\n",
       "81818    115246.0     6512\n",
       "81819    115247.0    76978\n",
       "81820    115248.0    93870\n",
       "81821    115249.0    71912\n",
       "81822    115252.0    34108\n",
       "81823    115253.0    35929\n",
       "81824    115254.0    24939\n",
       "81825    115255.0    37494\n",
       "81826    115256.0    51289\n",
       "81827    115257.0     7715\n",
       "81828    115258.0     3938\n",
       "81829    115259.0    13779\n",
       "81830    115260.0    81884\n",
       "81831    115261.0      673\n",
       "81832    115262.0      673\n",
       "81833    115265.0    49627\n",
       "\n",
       "[81834 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manipulate id2groups to assign random unique lineages to plasmids without a lineage \n",
    "\n",
    "#update id2lineage with removal of test_baseline ids \n",
    "id2lineage = id2lineage.loc[~id2lineage['addgene_id'].isin(test_baseline['addgene_id'])]\n",
    "\n",
    "#Set Seed\n",
    "random.seed(45)  \n",
    "\n",
    "#Generate Random numbers that are unique and different than the already existing lineage labels (they are above the max label)\n",
    "#The max lineage id is 1228 so any number above that will be a dummy index\n",
    "\n",
    "#Make dataframe of plasmids with no lineage and assign them a dummy lineage\n",
    "dummy_lineage = pd.DataFrame( columns=['addgene_id','lineage'])\n",
    "\n",
    "dummy_lineage['addgene_id'] = no_lineage_plasmids\n",
    "dummy_lineage['lineage'] = random.sample((range(1300,100000)),no_lineage_plasmids.size)\n",
    "\n",
    "#Combine id2lineage and dummy lineage to have a full dataframe of lineages \n",
    "lineages_full = pd.concat([id2lineage,dummy_lineage])\n",
    "lineages_full=lineages_full.sort_values(by=['addgene_id'])\n",
    "lineages_full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace lineage column with lineage ids including dummy ids \n",
    "addgene_full2['lineage'] = lineages_full['lineage'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save new version of addgene_full with baseline data taken away\n",
    "addgene_full2 = addgene_full2.loc[~addgene_full2['addgene_id'].isin(test_baseline['addgene_id'])]\n",
    "addgene_full2 = addgene_full2.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Group Splitting\n",
    "#Inputs: df-Pandas df\n",
    "#y_col-String name of column with values to be predicted in mode\n",
    "#groups_col-String name of column with values specifying group membership (This would be a lineage column in our case ie. which lineage a plasmid belonged to)\n",
    "\n",
    "def grouped_split(df,y_col, groups_col):\n",
    "    \n",
    "    #Split into Training set and combined Validation+Test set (First Step)\n",
    "    rs1 = 42\n",
    "    y1 = df[y_col]\n",
    "    groups1 = df[groups_col]\n",
    "    gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state= rs1)\n",
    "    train_inds, val_test_inds = next(gss1.split(X=df, y=y1, groups=groups1))\n",
    "    X_train, X_val_test, y_train, y_val_test = df.iloc[train_inds],df.iloc[val_test_inds], y1.iloc[train_inds], y1.iloc[val_test_inds]\n",
    "    \n",
    "    #Split Combined Validation+Test Sets into seperate Validation and Test Sets \n",
    "    rs2 = 43\n",
    "    y2 = X_val_test['lab']\n",
    "    groups2 = X_val_test[groups_col]\n",
    "    gss2 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state= rs2)\n",
    "    val_inds, test_inds = next(gss2.split(X=X_val_test, y=y2, groups=groups2))\n",
    "\n",
    "    X_val, X_test, y_val, y_test = X_val_test.iloc[val_inds], X_val_test.iloc[test_inds], y2.iloc[val_inds], y2.iloc[test_inds]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the split\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = grouped_split(addgene_full2,'lab','lineage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine test base X_test \n",
    "X_test = pd.concat([X_test,test_baseline])\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = pd.concat([y_test,test_baseline['lab'].to_frame()])\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop lab and lab_id column in data splots \n",
    "#X_val = X_val.drop(['lab','lab_id'], axis = 1)\n",
    "#X_train = X_train.drop(['lab','lab_id'], axis = 1)\n",
    "#X_test = X_test.drop(['lab','lab_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Replace Dummy Lineages with NaN as split is done \n",
    "X_train['lineage'] = X_train['lineage'].replace(dummy_lineage['lineage'].values, np.nan)\n",
    "X_val['lineage'] = X_val['lineage'].replace(dummy_lineage['lineage'].values, np.nan)\n",
    "X_test['lineage'] = X_test['lineage'].replace(dummy_lineage['lineage'].values, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save splits as CSVs (these are with the <10 grouping)\n",
    "X_val.to_pickle('X_val_baseline.pickle')\n",
    "y_val.to_pickle('y_val_baseline.pickle')\n",
    "\n",
    "X_test.to_pickle('X_test_baseline.pickle')\n",
    "y_test.to_pickle('y_test_baseline.pickle')\n",
    "\n",
    "X_train.to_pickle('X_train_baseline.pickle')\n",
    "y_train.to_pickle('y_train_baseline.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
